<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Smitha Sheshadri's portfolio. Research on Natural Language Interfaces, Human-Computer Interaction, and Indoor Localization and Tracking.">
<meta name="keywords" content="Smitha Sheshadri, Human-Computer Interaction, Indoor Localization, Singapore Management University">
<meta name="author" content="Smitha Sheshadri">
    <title>Smitha Sheshadri | Computer Science PhD</title>
    
    <link rel="stylesheet" href="css/style.css">
    <link rel="icon" type="image/png" href="favicon1.png">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=DM+Sans:wght@400&display=swap">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@400&family=Merriweather:wght@400&display=swap">
</head>
<body>
    <header>
        <nav>
            <div class="nav-container">
                <span class="logo">Smitha Sheshadri</span>
                <ul class="nav-links">
                    <li><a href="#about">About</a></li>
                    <li><a href="#projects-publications">Projects & Publications</a></li>
                    <li><a href="#highlights-happenings">Highlights & Happenings</a></li>
                    <li><a href="#beyond-research">Beyond Research</a></li>
                </ul>

                <button id="dark-mode-toggle" class="dark-mode-btn">
                    <i class="fas fa-moon"></i>
                </button>
            </div>
        </nav>
    </header>
    <section id="about" class="section">
        <div class="about-container">
            <div class="about-left">
                <img src="images/portfolio.PNG" alt="Profile Image" class="profile-img">
                <h2>Smitha Sheshadri</h2>
                <p class="subtitle">PhD Student in Computer Science</p>
                                <p class="subtitle">Singapore Management University</p>

            </div>
            <div class="about-right">
                <h1>About Me</h1>
<p>Iâ€™m Smitha, a PhD candidate in Human-Computer Interaction at Singapore Management University (SMU). My work focuses on developing solutions for indoor positioning using conversational interaction. Iâ€™m especially interested in how natural language, when combined with sensor data and behavioral models, can unlock new possibilities in spatial intelligence, a domain where language is still underused.</p>

<p>My current research explores how conversational input can drive concrete performance improvements in positioning systems for indoor spaces. By integrating natural language interaction into positioning systems, I aim to design low-cost, infrastructure-free approaches that are both practical and human-centered.</p>

<p>Before my PhD, I completed my masterâ€™s at the National University of Singapore (NUS), where I investigated how sensorimotor engagement through haptic touchscreen interfaces could enhance second-language vocabulary learning.</p> <p> Across projects, I specialize in rapid prototyping (Python is my go-to), user-centered design with iterative pilots, and user behavior analysis. Outside research, Iâ€™m always up for discovering new food spots and never get tired of rewatching Jurassic Park ðŸ¦–.</p>
                
                <!-- Interests & Education Subsections -->
                <div class="about-subsections">
                    <div class="interests-education">
<div class="interests">
    <h2>Interests</h2>
    <ul>
        <li>Natural Language & Conversational Interfaces</li>
        <li>User-as-sensor Solutions</li>
        <li>Indoor Spatial Intelligence</li>
        <li>Language Learning</li>

    </ul>
</div>

                        <div class="education">
                            <h2>Education</h2>
                            <ul>
                                <li><strong>PhD in Computer Science</strong>, 2022 - Present
                                    <div class="school">Singapore Management University (SMU)</div>
                                </li>
                                <li><strong>MSc in Computer Science</strong>, 2018 - 2020
                                    <div class="school">National University of Singapore (NUS)</div>
                                </li>
                                <li><strong>B.Eng in Computer Science and Engineering</strong>, 2014 - 2018
                                    <div class="school">Visvesvaraya Technological University, India</div>
                                </li>
                            </ul>
                        </div>
                    </div>
                </div>

            </div>
        </div>
    </section>
<section id="projects-publications" class="section">
    <div class="container">
        <h1>Projects & Publications</h1>
    <div class="project-publication">
        <div class="project-publication-details">
            <h2>Sensing isn't enough! Supporting Inertial Indoor Tracking with Conversational Input</h2>
            <img src="images/inertial_tracking.png" alt="Inertial Tracking Project" class="right">
            <p>
                We developed a low-cost indoor tracking system that improves inertial sensor accuracy by incorporating user-provided conversational cues. Our approach combines smartphone IMU data with natural language descriptions of known indoor locations, enabling accurate tracking without requiring pre-installed infrastructure or situated data collection.
            </p>
            <ul>
                <li>
                    <strong>Enhancing Smartphone-based Inertial Indoor Tracking with Conversational User Input</strong><br>
                    S. Sheshadri, K. Hara<br>
                    <em>IMWUT 2025</em>
                </li>
            </ul>
        </div>
    </div>

        <!-- Indoor Localization Project -->
        <div class="project-publication">
            <div class="project-publication-details">
                <h2>Indoor Human Localization through Intelligent Conversation</h2>
                <img src="images/indoor_localization2.png" alt="Indoor Localization Project" class="right">
                <p>
                    We developed <i>Conversational Localization</i>, a sensorless indoor localization approach using natural language interactions. Our system estimates user location based on described surroundings, employing strategies to extract the most useful details.
                </p>
                <ul>
                    <li>
                        <strong>Conversational Localization: Indoor Human Localization through Intelligent Conversation</strong><br>
                        S. Sheshadri, K. Hara<br>
                        <em>IMWUT 2024</em>
                    </li>
                    <li>
                        <strong>Feasibility Studies in Indoor Localization through Intelligent Conversation</strong><br>
                        S. Sheshadri, L. Cheng, K. Hara<br>
                        <em>CHI EA 2022</em>
                    </li>
                </ul>
            </div>
        </div>

        <!-- Haptics Learning Project -->
        <div class="project-publication">
            <div class="project-publication-details">
                <h2>Learn with Haptics: Improving Vocabulary Recall</h2>
                <img src="images/haptics-learning.png" alt="Haptics Learning Project" class="right">
                <p>Sensorimotor activation enhances learning, and we applied this principle to digital vocabulary learning by incorporating free-form digital annotation in mobile flashcard interfaces. By varying annotation type, presentation sequence, and haptic feedback, we identified a design that significantly improved retention, yielding a 24.21% increase in immediate recall and 30.36% improvement in 7-day delayed recall.</p>
                <ul>
                    <li>
                        <strong>Learn with Haptics: Improving Vocabulary Recall with Free-form Digital Annotation on Touchscreen Mobiles</strong><br>
                        S. Sheshadri, S. Zhao, Y. Chen, M. Fjeld<br>
                        <em>CHI 2020</em>
                    </li>
                </ul>
            </div>
        </div>
    </div>
</section>


<section id="highlights-happenings" class="section">
    <div class="container">
 <h1>Highlights & Happenings</h1>
       <div class="recognition-grid">

<div class="recognition-block">
  <img src="images/Tsinghua.png" alt="Interactive session for Undergrads">
  <div class="recognition-content">
    <h2>Academic Exchange: Hosting Undergrads from Tsinghua University</h2>
    <p>Conducted an interactive session for Xingya College (Tsinghua University) students at SMU, introducing indoor positioning and demoing my latest work. Fantastic energy and sharp questions!</p>
  </div>
</div>

           
<!--ICHECH-->
<div class="recognition-block">
  <img src="images/ichec.jpg" alt="Hosting a conference at SMU!">
  <div class="recognition-content">
    <h2>November 2025 â€“ SMU Buzzing with HCI Enthusiasts</h2>
    <p>Hosting ICHEC at SMU was fantastic! Volunteering gave us closer access to all the action, making the experience even more exciting and memorable.</p>
  </div>
</div>
           
           <!--IMWUT 2025-->
<div class="recognition-block"> <img src="images/imwut3.png" alt="Accepted to IMWUT!"> <div class="recognition-content"> <h2>IMWUT 2025!</h2> <p>Thrilled to share that our work was accepted to IMWUT / UbiComp 2025! We enabled smartphone-only tracking by strategically integrating conversational interaction, advancing continuous indoor localization without extra infrastructure.</p> </div> </div>

<!--Invited Speaker at FIT 2025-->
<div class="recognition-block">
    <img src="images/fit2025.png" alt="Invited Speaker at FIT2025">
    <div class="recognition-content">
        <h2>Invited Speaker at FIT2025</h2>
<p>Excited to be an invited speaker at FIT2025, presenting my work on Conversational Localization (September 2025)</p>
    </div>
</div>
           
<!--Testing in mall and museum-->
<div class="recognition-block">
    <img src="images/real-world.png" alt="Prototyping Demo in Mall and Museum">
    <div class="recognition-content">
        <h2>Prototyping in the Wild</h2>
<p>We recently tested our indoor tracking system in a museum and a mall. It was a fun chance to see our research in action. Huge thanks to the wonderful participants! (July 2025)</p>
    </div>
</div>
            <!-- Presidential Doctoral Fellowship Award -->
            <div class="recognition-block">
                <img src="images/fellowship.png" alt="Presidential Doctoral Fellowship">
                <div class="recognition-content">
                    <h2>Presidential Doctoral Fellowship Award 2024-25</h2>
                    <p>I received the award for my research contributions in natural language interfaces for indoor spatial intelligence, emphasizing sensorless localization.</p>
                </div>
            </div>
            <!-- Singapore HCI Meetup 2025 -->
            <div class="recognition-block">
                <img src="images/sghci25.png" alt="SG HCI 2025 Meetup">
                <div class="recognition-content">
                    <h2>Singapore HCI Meetup 2025</h2>
                    <p>Met some lovely folks at the SG HCI Meetup 2025, where I demoed my work on conversationally improving indoor smartphone tracking.</p>
                </div>
            </div>

            <!-- IMWUT 2024 Presentation -->
            <div class="recognition-block">
                <img src="images/imwut_presentation.jpg" alt="IMWUT 2024 Presentation">
                <div class="recognition-content">
                    <h2>IMWUT 2024 Presentation</h2>
                    <p>I had a great time presenting our work in IMWUT 2024, held in Melbourne. </p>
                </div>
            </div>


            <!-- MOE Academic Research Council Demo -->
            <div class="recognition-block">
                <img src="images/moe_arc_demo.jpg" alt="MOE ARC Demo">
                <div class="recognition-content">
                    <h2>Demo at MOE Academic Research Council (ARC) Site Visit</h2>
                    <p>At the Ministry of Education (MOE) Academic Research Council (ARC) Site Visit, I engaged with academic leaders and policymakers, discussing research and exchanging insights on human-centered technology.</p>
                </div>
            </div>

            <!-- Global Young Scientists Summit 2024 -->
            <div class="recognition-block">
                <img src="images/gyss_demo.jpg" alt="GYS Summit 2024">
                <div class="recognition-content">
                    <h2>Sharing with Global Young Scientists Summit 2024</h2>
                    <p>I had the opportunity to share my work with young researchers from around the world at GYSS 2024, engaging in discussions and exchanging ideas with peers and experts.</p>
                </div>
            </div>

            <!-- Singapore HCI Meetup 2024 -->
            <div class="recognition-block">
                <img src="images/singapore_hci_poster.jpg" alt="Singapore HCI Meetup 2024">
                <div class="recognition-content">
                    <h2>Singapore HCI Meetup 2024</h2>
                    <p>The Singapore HCI Meetup is a national gathering of researchers, designers, and practitioners. At the 2024 event, I presented my ongoing work and engaged with experts in human-centered technology.</p>
                </div>
            </div>

        </div>
    </div>
</section>





<section id="beyond-research" class="section">
    <div class="container">
        <h1>Beyond Research</h1>
        <ul>
            <li><strong>Teaching Assistant:</strong> Assisted in Computational Interaction (CS702) at Singapore Management University (SMU) for AY2024-25 Term 2 and AY2023-24 Term 2.</li>
            <li><strong>Volunteer Teaching:</strong> Worked with Make A Difference (MAD), a non-profit supporting shelter home children in India. Taught 5th-grade Science (2016-17) and later led 90+ volunteers (2017-18).</li>
        </ul>
    </div>
</section>

<footer>
    <p>
        &copy; 2025 Smitha Sheshadri. All rights reserved.
        &nbsp; | &nbsp;
        <a href="https://scholar.google.com/citations?user=ttvQCJsAAAAJ&hl=en&oi=ao" target="_blank">Google Scholar</a>
        &nbsp; | &nbsp;
        <a href="https://www.linkedin.com/in/smitha-sheshadri/" target="_blank">LinkedIn</a>
    </p>
</footer>


    <script>
        document.getElementById('dark-mode-toggle').addEventListener('click', function() {
            document.body.classList.toggle('dark-mode');
        });
    </script>
</body>
</html>
